{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIONAL INDEX IS :\n",
      "{'angel': [3, {7: [0], 8: [0], 9: [0]}], 'antoni': [3, {1: [0], 2: [0], 6: [0]}], 'brutu': [3, {1: [1], 2: [1], 4: [0]}], 'caeser': [5, {1: [2], 2: [2], 4: [1], 5: [0], 6: [1]}], 'calpurnia': [1, {2: [3]}], 'cleopatra': [1, {1: [3]}], 'fear': [3, {7: [2], 8: [2], 10: [1]}], 'fool': [4, {7: [1], 8: [1], 9: [1], 10: [0]}], 'in': [4, {7: [3], 8: [3], 9: [2], 10: [2]}], 'merci': [5, {1: [4], 3: [0], 4: [2], 5: [1], 6: [2]}], 'rush': [4, {7: [4], 8: [4], 9: [3], 10: [3]}], 'to': [4, {7: [5], 8: [5], 9: [4], 10: [4]}], 'tread': [4, {7: [6], 8: [6], 9: [5], 10: [5]}], 'where': [4, {7: [7], 8: [7], 9: [6], 10: [6]}], 'worser': [4, {1: [5], 3: [1], 4: [3], 5: [2]}]}\n",
      "\n",
      "\n",
      "TERM FREQUENCY IS:\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "angel         0     0     0     0     0     0     1     1     1      0\n",
      "antoni        1     1     0     0     0     1     0     0     0      0\n",
      "brutu         1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "fool          0     0     0     0     0     0     1     1     1      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "merci         1     0     1     1     1     1     0     0     0      0\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "\n",
      "\n",
      "WT_TF IS:\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "angel       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "antoni      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutu       1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "fool        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "merci       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "\n",
      "\n",
      "DF AND IDF IS :\n",
      "          d_f       idf\n",
      "angel       3  0.522879\n",
      "antoni      3  0.522879\n",
      "brutu       3  0.522879\n",
      "caeser      5   0.30103\n",
      "calpurnia   1       1.0\n",
      "cleopatra   1       1.0\n",
      "fear        3  0.522879\n",
      "fool        4   0.39794\n",
      "in          4   0.39794\n",
      "merci       5   0.30103\n",
      "rush        4   0.39794\n",
      "to          4   0.39794\n",
      "tread       4   0.39794\n",
      "where       4   0.39794\n",
      "worser      4   0.39794\n",
      "\n",
      "\n",
      "TF_IDF IS :\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "angel           0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "antoni     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutu      0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fool            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "merci       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "angel      0.522879  0.522879       0.0  \n",
      "antoni          0.0       0.0       0.0  \n",
      "brutu           0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "fool        0.39794   0.39794   0.39794  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "merci           0.0       0.0       0.0  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "worser          0.0       0.0       0.0  \n",
      "\n",
      "\n",
      "DOCUMENT LENGTH IS :\n",
      "   doc1_len  doc2_len  doc3_len  doc4_len  doc5_len  doc6_len  doc7_len  \\\n",
      "0  1.373462  1.279618  0.498974  0.782941  0.582747   0.67427  1.223496   \n",
      "\n",
      "   doc8_len  doc9_len  doc10_len  \n",
      "0  1.223496  1.106137   1.106137  \n",
      "\n",
      "\n",
      "NORMALIZTION\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "angel      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "antoni     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
      "brutu      0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fool       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "merci      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "angel      0.427365  0.427365  0.472707  0.000000  \n",
      "antoni     0.000000  0.000000  0.000000  0.000000  \n",
      "brutu      0.000000  0.000000  0.000000  0.000000  \n",
      "caeser     0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
      "fear       0.427365  0.427365  0.000000  0.472707  \n",
      "fool       0.325248  0.325248  0.359756  0.359756  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "merci      0.000000  0.000000  0.000000  0.000000  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n",
      "worser     0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" nltk.download('puntk')\n",
    "nltk.download('stopwords') \"\"\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from natsort import natsorted\n",
    "import os \n",
    "import nltk\n",
    "import math\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('to')\n",
    "stop_words.remove('in')\n",
    "stop_words.remove('where')\n",
    "\n",
    "#READ documents And TOKENIZATION And STEEMING\n",
    "ps = PorterStemmer()\n",
    "document_of_terms = []\n",
    "document_with_stemming = []\n",
    "file_name = natsorted(os.listdir('../DocumentCollection')) #to sort files in folder\n",
    "for file in file_name :\n",
    "    #1.1# Read 10 Documents\n",
    "    with open(f'../DocumentCollection/{file}', 'r') as f:\n",
    "        document = f.read()\n",
    "    #1.2# apply tokenizing\n",
    "    tokenizing = word_tokenize(document)\n",
    "    for word in tokenizing : \n",
    "        if word not in stop_words :\n",
    "            #1.3# apply stemming\n",
    "            stemming = ps.stem(word)\n",
    "        document_with_stemming.append(stemming)\n",
    "    document_of_terms.append(document_with_stemming)\n",
    "    document_with_stemming = []\n",
    "#print(document_of_terms)\n",
    "\n",
    "# positional index\n",
    "document_id = 1\n",
    "positional_index = {}\n",
    "for document in document_of_terms:\n",
    "    for position, term in enumerate(document):\n",
    "        if term in positional_index:\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "            if document_id in positional_index[term][1]:\n",
    "                positional_index[term][1][document_id].append(position)\n",
    "            else:\n",
    "                positional_index[term][1][document_id] = [position]\n",
    "        else:\n",
    "            positional_index[term] = []\n",
    "            positional_index[term].append(1)\n",
    "            positional_index[term].append({})\n",
    "            positional_index[term][1][document_id] = [position]\n",
    "    document_id = document_id + 1\n",
    "sorted_posIndex = dict(sorted(positional_index.items()))\n",
    "print(\"POSITIONAL INDEX IS :\")\n",
    "print(sorted_posIndex)\n",
    "print()\n",
    "print()\n",
    "\n",
    "#2.5# phrase query\n",
    "outer_array = [[] for i in range(10)]\n",
    "query = \"fools fear\"\n",
    "for wordd in query.split():\n",
    "    word_after_stem = ps.stem(wordd)\n",
    "    if word_after_stem in positional_index.keys():  \n",
    "      for key in positional_index[word_after_stem][1].keys():\n",
    "        if outer_array[key-1] != []:\n",
    "            if outer_array[key-1][-1] == positional_index[word_after_stem][1][key][0] - 1:\n",
    "                    outer_array[key-1].append(positional_index[word_after_stem][1][key][0])\n",
    "        else:\n",
    "                outer_array[key-1].append(positional_index[word_after_stem][1][key][0])\n",
    "for position, arr in enumerate(outer_array, start=1):\n",
    "       if len(arr) == len(query.split()):\n",
    "            x = position \n",
    "            #print(position)\n",
    "\n",
    "#tf\n",
    "all_terms = []\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_terms.append(word)\n",
    "def term_frequency(doc):\n",
    "    #put each term in dictionary form with value 0\n",
    "    word_count = dict.fromkeys(all_terms, 0) \n",
    "    for word in doc:\n",
    "        #increment the value of each term in dictionary\n",
    "        word_count[word] += 1\n",
    "        # return dictionary of each document\n",
    "    return word_count\n",
    "# convert dictionay form into columns form\n",
    "tf = pd.DataFrame(term_frequency(document_of_terms[0]).values(), index = term_frequency(document_of_terms[0]). keys())\n",
    "for i in range(1, len(document_of_terms)):\n",
    "    tf[i] = term_frequency(document_of_terms[i]).values()\n",
    "#change name of column\n",
    "tf.columns = ['doc' + str(i) for i in range(1, 11)] \n",
    "sorted_tf = tf.sort_index()\n",
    "print(\"TERM FREQUENCY IS:\")\n",
    "print(sorted_tf)\n",
    "print()\n",
    "print()\n",
    "\n",
    "#w_tf weighted term frequency 1 + log10(tf)\n",
    "def w_tf(x):\n",
    "    if x > 0:\n",
    "        return math.log10(x) + 1\n",
    "    else:\n",
    "        return 0\n",
    "wt_tf = tf.copy()\n",
    "for i in range(1, len(document_of_terms) + 1):\n",
    "    #replace each raw with w_tf\n",
    "    wt_tf['doc'+ str(i)] =  wt_tf['doc'+str(i)].apply(w_tf) \n",
    "sorted_wt_tf = wt_tf.sort_index()\n",
    "print(\"WT_TF IS:\")\n",
    "print(sorted_wt_tf)\n",
    "print()\n",
    "print()\n",
    "\n",
    "#2.3# IDF\n",
    "df_and_IDF = pd.DataFrame(columns=('d_f','idf'))\n",
    "for i in range(len(tf)):\n",
    "    doc_freq = tf.iloc[i].values.sum()\n",
    "    df_and_IDF.loc[i, 'd_f'] = doc_freq\n",
    "    df_and_IDF.loc[i, 'idf'] = math.log10(10/float(doc_freq))\n",
    "df_and_IDF.index = tf.index\n",
    "sorted_df_and_IDF = df_and_IDF.sort_index()\n",
    "print(\"DF AND IDF IS :\")\n",
    "print(sorted_df_and_IDF)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# TF-IDF\n",
    "tf_idf = tf.multiply(df_and_IDF['idf'], axis = 0)\n",
    "sorted_tf_idf = tf_idf.sort_index()\n",
    "print(\"TF_IDF IS :\")\n",
    "print(sorted_tf_idf)\n",
    "print()\n",
    "print()\n",
    "\n",
    "#doc_length\n",
    "import numpy as np\n",
    "doc_length = pd.DataFrame()\n",
    "def document_length(col):\n",
    "    return np.sqrt(tf_idf[col].apply(lambda x: x**2).sum())\n",
    "for column in tf_idf.columns:\n",
    "    doc_length.loc[0, column + '_len'] = document_length(column)\n",
    "print(\"DOCUMENT LENGTH IS :\")\n",
    "print(doc_length)\n",
    "print()\n",
    "print()\n",
    "\n",
    "#NORMALIZATION TF-IDF divided by DOC_LENGTH\n",
    "normalize = pd.DataFrame()\n",
    "def get_normalize(col, x):\n",
    "    try:\n",
    "        return x / doc_length[column + '_len'].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "for column in tf_idf.columns:\n",
    "    normalize[column] = tf_idf[column].apply(lambda x: get_normalize(column, x))\n",
    "print(\"NORMALIZTION\")\n",
    "sorted_normalize = normalize.sort_index()\n",
    "print(sorted_normalize)\n",
    "print()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
